{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96TQ27A0Vmx9"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_E8J6S5V28j"
      },
      "outputs": [],
      "source": [
        "!pip install rouge_score\n",
        "\n",
        "!pip install nltk\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MashXIurCECK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f68750b-4b27-4031-ebd5-5d9280ef420a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Tshiluba_English_Dataset.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/105GRn0pQldcwPb_3C80TL0JXChjZq9h_\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from transformers import MarianMTModel, MarianTokenizer, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and preprocess English data"
      ],
      "metadata": {
        "id": "yfXsLDj1xwEB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH0I5-FXjVau"
      },
      "outputs": [],
      "source": [
        "english_data = pd.read_csv('/content/drive/My Drive/English_Mathew_Data.csv')\n",
        "\n",
        "# Split 'Verse' into 'Number' and 'Text'\n",
        "english_data[['Number', 'Text']] = english_data['Verse Text'].str.extract(r'^(\\d+)(.*)')\n",
        "\n",
        "# Drop the original 'Verse' column\n",
        "english_data.drop(columns=['Verse Text'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and preprocess Tshiluba data"
      ],
      "metadata": {
        "id": "EEOYg2FhxsRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/Tshiluba_Matthew_Data.csv'\n",
        "tshiluba_data = pd.read_csv(file_path, encoding=\"latin-1\")\n",
        "tshiluba_data.drop(\"Unnamed: 2\", axis=1, inplace=True)\n",
        "tshiluba_data.replace('Â“', '', regex=True, inplace=True)"
      ],
      "metadata": {
        "id": "2PBgpgdcxqb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine Data"
      ],
      "metadata": {
        "id": "eDWjzGNdx0lz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDk3anYcjfvY"
      },
      "outputs": [],
      "source": [
        "parallel_data = pd.concat([tshiluba_data, english_data], axis=1)\n",
        "parallel_data.drop(\"Number\", axis=1, inplace=True)\n",
        "parallel_data.to_csv(\"/content/drive/My Drive/Cleaned_Parallel_Data.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the necessary libraries"
      ],
      "metadata": {
        "id": "P-40PWknx33s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, AutoModelForSeq2SeqLM, AutoTokenizer, TrainerCallback\n",
        "import optuna\n",
        "from datasets import load_metric\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ijxI8qxJxAka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Functions"
      ],
      "metadata": {
        "id": "MbLBS_chy7Yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    \"\"\"\n",
        "    Preprocesses the input examples for the translation task.\n",
        "\n",
        "    Args:\n",
        "        examples (dict): A dictionary containing 'Verse Text' and 'Text' as keys.\n",
        "                         'Verse Text' contains the source text, and 'Text' contains the target text.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing tokenized inputs and labels, ready for model training.\n",
        "              The dictionary includes:\n",
        "              - 'input_ids': Tokenized input IDs with padding and truncation.\n",
        "              - 'attention_mask': Attention mask for the tokenized inputs.\n",
        "              - 'labels': Tokenized target IDs with padding and truncation.\n",
        "    \"\"\"\n",
        "    inputs = examples['Verse Text']\n",
        "    targets = examples['Text']\n",
        "\n",
        "    # Tokenize inputs with padding and truncation\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Tokenize targets using the target tokenizer\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Add the tokenized labels to the model inputs\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs\n"
      ],
      "metadata": {
        "id": "p0U-WsOJxEEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    \"\"\"\n",
        "    Computes the BLEU score for the predictions.\n",
        "\n",
        "    Args:\n",
        "        pred (EvalPrediction): An object containing predictions and labels from the model.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with the BLEU score for the predictions.\n",
        "              The dictionary includes:\n",
        "              - 'bleu': The BLEU score as a float.\n",
        "    \"\"\"\n",
        "    # Access the logits from predictions\n",
        "    logits = pred.predictions[0]\n",
        "    # Get the predicted token IDs by taking the argmax along the last dimension\n",
        "    pred_ids = logits.argmax(axis=-1)\n",
        "    # Decode the predicted token IDs to text\n",
        "    pred_texts = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Get the label IDs and replace -100 with the pad token ID\n",
        "    labels_ids = pred.label_ids\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    # Decode the label IDs to text\n",
        "    labels_texts = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    # Strip leading/trailing whitespace from the decoded texts\n",
        "    pred_texts = [text.strip() for text in pred_texts]\n",
        "    labels_texts = [text.strip() for text in labels_texts]\n",
        "\n",
        "    # Compute BLEU score using the decoded texts\n",
        "    bleu_score = bleu_metric.compute(predictions=[pred.split() for pred in pred_texts], references=[[label.split()] for label in labels_texts])\n",
        "\n",
        "    return {\"bleu\": bleu_score[\"bleu\"]}\n"
      ],
      "metadata": {
        "id": "hgp4nBtbxN3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mock_objective(trial):\n",
        "    \"\"\"\n",
        "    A mock objective function for Optuna optimization.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): An Optuna trial object used to suggest hyperparameters.\n",
        "\n",
        "    Returns:\n",
        "        float: A mock score calculated based on suggested hyperparameters.\n",
        "    \"\"\"\n",
        "    # Suggest hyperparameters for the trial\n",
        "    num_train_epochs = trial.suggest_int('num_train_epochs', 1, 10)\n",
        "    batch_size = trial.suggest_categorical('per_device_train_batch_size', [1, 2])\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
        "    gradient_accumulation_steps = trial.suggest_int('gradient_accumulation_steps', 1, 16)\n",
        "    weight_decay = trial.suggest_float('weight_decay', 0.0, 0.3)\n",
        "\n",
        "    # Compute a mock score based on the suggested hyperparameters\n",
        "    mock_score = (\n",
        "        (num_train_epochs * learning_rate) / (batch_size * gradient_accumulation_steps)\n",
        "        - weight_decay\n",
        "    )\n",
        "\n",
        "    # Add random noise to the mock score\n",
        "    noise = trial.suggest_uniform('noise', 0.0, 0.1)\n",
        "    mock_score += noise\n",
        "\n",
        "    return mock_score\n"
      ],
      "metadata": {
        "id": "4aWcqEbCxRYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainerCallback\n",
        "\n",
        "class PrintLossCallback(TrainerCallback):\n",
        "    \"\"\"\n",
        "    A custom callback for the Hugging Face Trainer that prints training and evaluation loss values.\n",
        "\n",
        "    Inherits from:\n",
        "        TrainerCallback: The base callback class provided by the Hugging Face `transformers` library.\n",
        "\n",
        "    Methods:\n",
        "        on_log(args, state, control, logs=None, **kwargs):\n",
        "            Called when logs are available, prints training and evaluation loss values.\n",
        "    \"\"\"\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Callback function that prints the loss values during training and evaluation.\n",
        "\n",
        "        Args:\n",
        "            args (TrainingArguments): The training arguments.\n",
        "            state (TrainerState): The current state of the trainer.\n",
        "            control (TrainerControl): The control object used to manage training.\n",
        "            logs (dict, optional): A dictionary containing logs such as 'loss' and 'eval_loss'.\n",
        "            **kwargs: Additional keyword arguments.\n",
        "        \"\"\"\n",
        "        if logs:\n",
        "            if 'loss' in logs:\n",
        "                print(f\"Training loss: {logs['loss']}\")\n",
        "            if 'eval_loss' in logs:\n",
        "                print(f\"Evaluation loss: {logs['eval_loss']}\")\n"
      ],
      "metadata": {
        "id": "1pxBThGLxU_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "model_name = \"Helsinki-NLP/opus-mt-mul-en\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Convert DataFrame to Dataset\n",
        "dataset = Dataset.from_pandas(parallel_data)\n",
        "dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Split dataset into train and eval\n",
        "dataset_dict = dataset.train_test_split(test_size=0.1)\n",
        "train_dataset = dataset_dict['train']\n",
        "eval_dataset = dataset_dict['test']\n",
        "\n",
        "# Define evaluation metrics function\n",
        "bleu_metric = load_metric(\"bleu\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Optimize hyperparameters using Optuna\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(mock_objective, n_trials=5)\n",
        "\n",
        "# Extract best hyperparameters\n",
        "best_params = study.best_params\n",
        "print(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "\n",
        "# Load model for final training\n",
        "final_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "final_model.gradient_checkpointing_enable()\n",
        "\n",
        "# Set up final training arguments\n",
        "final_training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='./final_model',\n",
        "    num_train_epochs=best_params['num_train_epochs'],\n",
        "    per_device_train_batch_size=best_params['per_device_train_batch_size'],\n",
        "    per_device_eval_batch_size=best_params['per_device_train_batch_size'],\n",
        "    learning_rate=best_params['learning_rate'],\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir='./final_logs',\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    gradient_accumulation_steps=best_params.get('gradient_accumulation_steps', 1),\n",
        "    fp16=True,\n",
        "    save_total_limit=1,\n",
        "    weight_decay=best_params.get('weight_decay', 0.0),\n",
        "    report_to=\"none\"  # Disable TensorBoard to focus on print output\n",
        ")\n",
        "\n",
        "# Train the final model with best hyperparameters\n",
        "final_trainer = Seq2SeqTrainer(\n",
        "    model=final_model,\n",
        "    args=final_training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[PrintLossCallback()]  # Add custom callback here\n",
        ")\n",
        "\n",
        "final_trainer.train()\n",
        "\n",
        "# Save the best model and tokenizer\n",
        "model_save_path = '/content/drive/My Drive/New_best_model'\n",
        "tokenizer_save_path = '/content/drive/My Drive/New_best_tokenizer'\n",
        "final_model.save_pretrained(model_save_path)\n",
        "tokenizer.save_pretrained(tokenizer_save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a060ae5cbc464716919d58df886c3dbe",
            "57e88816a2ca421baf7762b730dc59fc",
            "fe80e3e530864aceb721293ca7a63f63",
            "c9d3502709e5439dad001a9457162dc6",
            "ebab1fc4c2a042ce990658474cd5f4ee",
            "ec6a908f2e9a474f832721c03fb4d8b8",
            "1c49451dd2364dc995f45ab663a1c5d4",
            "45b4c1708f6f432ca3ddd9fa723f8ffd",
            "08bdfd94107a4b76bcdf8d75c7cfd437",
            "6aa0b4313168478b9f0377180bfc65ad",
            "b6d012f1f16b49ccb7f09fc8e00400c9"
          ]
        },
        "id": "TIVE3uXbkj5j",
        "outputId": "ae458dd7-80a3-4f82-bc17-dd2863e58680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1071 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a060ae5cbc464716919d58df886c3dbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "[I 2024-08-05 22:15:22,365] A new study created in memory with name: no-name-5ea9bb4a-ee62-4407-b57e-916848fae498\n",
            "<ipython-input-31-150ec538ddb9>:62: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-4)\n",
            "<ipython-input-31-150ec538ddb9>:71: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  noise = trial.suggest_uniform('noise', 0.0, 0.1)\n",
            "[I 2024-08-05 22:15:22,369] Trial 0 finished with value: -0.19699082287325884 and parameters: {'num_train_epochs': 5, 'per_device_train_batch_size': 1, 'learning_rate': 3.6393434907557593e-06, 'gradient_accumulation_steps': 13, 'weight_decay': 0.29643952184597544, 'noise': 0.09944729922522014}. Best is trial 0 with value: -0.19699082287325884.\n",
            "[I 2024-08-05 22:15:22,371] Trial 1 finished with value: 0.04279440304569726 and parameters: {'num_train_epochs': 6, 'per_device_train_batch_size': 1, 'learning_rate': 4.3410134215112175e-05, 'gradient_accumulation_steps': 16, 'weight_decay': 0.002846863409696565, 'noise': 0.045624987655063155}. Best is trial 1 with value: 0.04279440304569726.\n",
            "[I 2024-08-05 22:15:22,374] Trial 2 finished with value: -0.046030452121831225 and parameters: {'num_train_epochs': 5, 'per_device_train_batch_size': 1, 'learning_rate': 5.529284867143106e-05, 'gradient_accumulation_steps': 9, 'weight_decay': 0.1298094745521051, 'noise': 0.08374830418101196}. Best is trial 1 with value: 0.04279440304569726.\n",
            "[I 2024-08-05 22:15:22,376] Trial 3 finished with value: 0.006652114477233108 and parameters: {'num_train_epochs': 9, 'per_device_train_batch_size': 2, 'learning_rate': 7.162700766482308e-05, 'gradient_accumulation_steps': 5, 'weight_decay': 0.045023753112236393, 'noise': 0.05161140328257116}. Best is trial 1 with value: 0.04279440304569726.\n",
            "[I 2024-08-05 22:15:22,378] Trial 4 finished with value: -0.244950001306608 and parameters: {'num_train_epochs': 10, 'per_device_train_batch_size': 1, 'learning_rate': 3.162625518595993e-06, 'gradient_accumulation_steps': 14, 'weight_decay': 0.2514214588494767, 'noise': 0.006469198524641118}. Best is trial 1 with value: 0.04279440304569726.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'num_train_epochs': 6, 'per_device_train_batch_size': 1, 'learning_rate': 4.3410134215112175e-05, 'gradient_accumulation_steps': 16, 'weight_decay': 0.002846863409696565, 'noise': 0.045624987655063155}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [360/360 08:27, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.232900</td>\n",
              "      <td>0.132436</td>\n",
              "      <td>0.636043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.157200</td>\n",
              "      <td>0.110929</td>\n",
              "      <td>0.679657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.097500</td>\n",
              "      <td>0.102456</td>\n",
              "      <td>0.714550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.075700</td>\n",
              "      <td>0.099765</td>\n",
              "      <td>0.717662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.098521</td>\n",
              "      <td>0.719461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.057000</td>\n",
              "      <td>0.097801</td>\n",
              "      <td>0.719773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.7224\n",
            "Training loss: 0.4735\n",
            "Training loss: 0.3315\n",
            "Training loss: 0.2498\n",
            "Training loss: 0.2352\n",
            "Training loss: 0.2329\n",
            "Evaluation loss: 0.13243593275547028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.1654\n",
            "Training loss: 0.1606\n",
            "Training loss: 0.1502\n",
            "Training loss: 0.1592\n",
            "Training loss: 0.1503\n",
            "Training loss: 0.1572\n",
            "Evaluation loss: 0.11092866212129593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.1126\n",
            "Training loss: 0.0932\n",
            "Training loss: 0.1052\n",
            "Training loss: 0.1096\n",
            "Training loss: 0.105\n",
            "Training loss: 0.0975\n",
            "Evaluation loss: 0.10245589911937714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.0798\n",
            "Training loss: 0.0816\n",
            "Training loss: 0.0823\n",
            "Training loss: 0.0794\n",
            "Training loss: 0.0752\n",
            "Training loss: 0.0757\n",
            "Evaluation loss: 0.09976517409086227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.0604\n",
            "Training loss: 0.0626\n",
            "Training loss: 0.0683\n",
            "Training loss: 0.064\n",
            "Training loss: 0.0701\n",
            "Training loss: 0.065\n",
            "Evaluation loss: 0.09852129966020584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.0557\n",
            "Training loss: 0.0608\n",
            "Training loss: 0.0554\n",
            "Training loss: 0.0534\n",
            "Training loss: 0.0617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.057\n",
            "Evaluation loss: 0.09780053794384003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n",
            "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.encoder.embed_positions.weight', 'model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'lm_head.weight'].\n",
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[64171]], 'forced_eos_token_id': 0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/New_best_tokenizer/tokenizer_config.json',\n",
              " '/content/drive/My Drive/New_best_tokenizer/special_tokens_map.json',\n",
              " '/content/drive/My Drive/New_best_tokenizer/vocab.json',\n",
              " '/content/drive/My Drive/New_best_tokenizer/source.spm',\n",
              " '/content/drive/My Drive/New_best_tokenizer/target.spm',\n",
              " '/content/drive/My Drive/New_best_tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a060ae5cbc464716919d58df886c3dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57e88816a2ca421baf7762b730dc59fc",
              "IPY_MODEL_fe80e3e530864aceb721293ca7a63f63",
              "IPY_MODEL_c9d3502709e5439dad001a9457162dc6"
            ],
            "layout": "IPY_MODEL_ebab1fc4c2a042ce990658474cd5f4ee"
          }
        },
        "57e88816a2ca421baf7762b730dc59fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec6a908f2e9a474f832721c03fb4d8b8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1c49451dd2364dc995f45ab663a1c5d4",
            "value": "Map:â€‡100%"
          }
        },
        "fe80e3e530864aceb721293ca7a63f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45b4c1708f6f432ca3ddd9fa723f8ffd",
            "max": 1071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08bdfd94107a4b76bcdf8d75c7cfd437",
            "value": 1071
          }
        },
        "c9d3502709e5439dad001a9457162dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aa0b4313168478b9f0377180bfc65ad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b6d012f1f16b49ccb7f09fc8e00400c9",
            "value": "â€‡1071/1071â€‡[00:00&lt;00:00,â€‡3154.46â€‡examples/s]"
          }
        },
        "ebab1fc4c2a042ce990658474cd5f4ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6a908f2e9a474f832721c03fb4d8b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c49451dd2364dc995f45ab663a1c5d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45b4c1708f6f432ca3ddd9fa723f8ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08bdfd94107a4b76bcdf8d75c7cfd437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6aa0b4313168478b9f0377180bfc65ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6d012f1f16b49ccb7f09fc8e00400c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
